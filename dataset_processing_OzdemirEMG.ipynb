{
 "cells": [
  {
   "cell_type": "code",

   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxwell/.local/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],

   "source": [
    "import numpy as np\n",
    "import scipy\n",

    "import scipy.io as sio\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import h5py"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": 5,

   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [

      "File DatasetsProcessed_hdf5/OzdemirEMG/p26/participant_26.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p2/participant_2.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p8/participant_8.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p31/participant_31.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p34/participant_34.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p10/participant_10.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p33/participant_33.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p15/participant_15.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p6/participant_6.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p7/participant_7.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p20/participant_20.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p36/participant_36.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p19/participant_19.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p38/participant_38.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p17/participant_17.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p27/participant_27.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p11/participant_11.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p35/participant_35.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p30/participant_30.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p37/participant_37.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p21/participant_21.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p28/participant_28.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p25/participant_25.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p5/participant_5.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p29/participant_29.hdf5 already exists. Skipping...\n",
      "File DatasetsProcessed_hdf5/OzdemirEMG/p14/participant_14.hdf5 already exists. Skipping...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to create file (file exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_103510/3386314826.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Open the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mhdf_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdf5_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 'x' mode to fail if exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File {hdf5_filename} already exists. Skipping...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 567\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'w-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to create file (file exists)"

     ]
    }
   ],
   "source": [
    "# Sampling rate \"Hz\"\n",
    "fs = 2000\n",
    "\n",
    "# Desired sEMG Segments Length in seconds\n",
    "# Erase old files to write new hdf5 files if you want to change this\n",
    "signal_segment_starting = 1 # amount of time delay after cue\n",
    "signal_segment_ending = 6 # amount of time after signal. 6 seconds is the end of the cue, so 5 or 6 are good numbers\n",
    "\n",
    "# Get sEMG Records directory\n",
    "current_folder = './OzdemirEMG/'  # Change with current folder\n",
    "Base = os.path.join(current_folder, 'sEMG-dataset/raw/mat')  # Change raw or filtered as needed\n",
    "Files = glob(os.path.join(Base, '**/*.mat'), recursive=True)\n",
    "# Files.sort()  # Sort files if needed\n",
    "\n",
    "                    \n",
    "# Automated segmentation and saving of all participant sEMG data to sEMG gesture segment in HDF5\n",
    "for file_path in Files:\n",
    "    foldername = 'DatasetsProcessed_hdf5/OzdemirEMG/'\n",
    "    mat_data = scipy.io.loadmat(file_path)\n",
    "    data = mat_data['data']\n",
    "    participant_id = mat_data['iD'][0][0]  # Modify based on where ID is stored in your .mat\n",
    "\n",
    "    # Create or open HDF5 file for each participant\n",
    "    foldername = os.path.join(foldername, 'p' + str(participant_id) + '/')\n",
    "    hdf5_filename = f'participant_{participant_id}.hdf5'\n",
    "    hdf5_filename = os.path.join(foldername, hdf5_filename)\n",
    "    # Make folders if they don't exist\n",
    "    os.makedirs(os.path.dirname(hdf5_filename), exist_ok=True)\n",
    "    # Open the file\n",
    "    try:\n",
    "        hdf_file = h5py.File(hdf5_filename, 'x')  # 'x' mode to fail if exists\n",
    "    except FileExistsError:\n",
    "        print(f\"File {hdf5_filename} already exists. Skipping...\")\n",
    "        continue\n",
    "    with h5py.File(hdf5_filename, 'a') as hdf_file:  # 'a' mode to append if already exists\n",
    "        \n",
    "        for rep in range(5):  # 5 repetitions\n",
    "            rep_coeff = [4, 138, 272, 406, 540][rep]\n",
    "\n",
    "            for gesture in range(10):  # Total of 10 hand gestures\n",
    "                start_idx = (signal_segment_starting + rep_coeff + (gesture * 10)) * fs\n",
    "                end_idx = ((rep_coeff + (gesture * 10)) + signal_segment_ending) * fs\n",
    "                \n",
    "                # Multi-channel sEMG data\n",
    "                multi_channel_sEMG_data = data[start_idx:end_idx, :].T\n",
    "\n",
    "                # Define a group for each gesture and cycle. Cycles act as hdf top-level keys \n",
    "                # and gestures act as sub-keys. 'sEMG' is the sole sub-sub-key for the data\n",
    "                group_name = f'Cycle{rep + 1}/Gesture{gesture_names[gesture]}'\n",
    "                grp = hdf_file.require_group(group_name)\n",
    "\n",
    "                # Save the data in the group, formatted as (CHANNEL, TIME)\n",
    "                grp.create_dataset('sEMG', data=multi_channel_sEMG_data, compression=\"gzip\")\n",
    "\n",
    "    print(f\"Data for participant {participant_id} and all gestures saved in {hdf5_filename}.\")"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 3,

   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [

      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p1/flattened_participant_1.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p2/flattened_participant_2.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p3/flattened_participant_3.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p4/flattened_participant_4.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p5/flattened_participant_5.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p6/flattened_participant_6.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p7/flattened_participant_7.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p8/flattened_participant_8.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p9/flattened_participant_9.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p10/flattened_participant_10.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p11/flattened_participant_11.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p12/flattened_participant_12.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p13/flattened_participant_13.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p14/flattened_participant_14.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p15/flattened_participant_15.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p16/flattened_participant_16.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p17/flattened_participant_17.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p18/flattened_participant_18.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p19/flattened_participant_19.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p20/flattened_participant_20.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p21/flattened_participant_21.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p22/flattened_participant_22.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p23/flattened_participant_23.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p24/flattened_participant_24.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p25/flattened_participant_25.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p26/flattened_participant_26.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p27/flattened_participant_27.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p28/flattened_participant_28.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p29/flattened_participant_29.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p30/flattened_participant_30.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p31/flattened_participant_31.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p32/flattened_participant_32.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p33/flattened_participant_33.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p34/flattened_participant_34.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p35/flattened_participant_35.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p36/flattened_participant_36.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p37/flattened_participant_37.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p38/flattened_participant_38.hdf5.\n",
      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p39/flattened_participant_39.hdf5.\n",

      "Reprocessed data saved in DatasetsProcessed_hdf5/OzdemirEMG/p40/flattened_participant_40.hdf5.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io  # For loading .mat files\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "#Flattened dataset with gestures as groups and numpy arrays of shape (CYCLE, CHANNEL, TIME)\n",
    "gesture_names = ['Rest', 'Extension', 'Flexion', 'Ulnar_Deviation', 'Radial_Deviation', 'Grip', 'Abduction', 'Adduction', 'Supination', 'Pronation']\n",
    "\n",
    "for i in range(1, 41):\n",
    "    foldername = 'DatasetsProcessed_hdf5/OzdemirEMG/'\n",
    "    foldername = os.path.join(foldername, 'p' + str(i) + '/')\n",
    "    hdf5_input_filename = f'participant_{i}.hdf5'\n",
    "    hdf5_input_filename = os.path.join(foldername, hdf5_input_filename)\n",
    "    hdf5_output_filename = f'flattened_participant_{i}.hdf5'\n",
    "    hdf5_output_filename = os.path.join(foldername, hdf5_output_filename)\n",
    "\n",
    "    try: \n",
    "        hdf5_input_file = h5py.File(hdf5_input_filename, 'r')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {hdf5_input_filename} not found. Skipping...\")\n",
    "        continue\n",
    "    # Open the existing HDF5 file to read\n",
    "    with h5py.File(hdf5_input_filename, 'r') as hdf_read:\n",

    "        '''\n",
    "        try:\n",
    "            hdf5_output_file = h5py.File(hdf5_output_filename, 'x')  # 'x' mode to fail if exists\n",
    "        except FileExistsError:\n",
    "            print(f\"File {hdf5_output_filename} already exists. Skipping...\")\n",
    "            continue\n",
    "        '''\n",
    "        # Open a new HDF5 file to write reprocessed data\n",
    "        with h5py.File(hdf5_output_filename, 'w') as hdf_write:\n",
    "            \n",
    "            # Iterate through each gesture (assuming 10 gestures)\n",
    "            for gesture in range(10):\n",
    "                all_cycles_data = []  # List to hold data from all cycles for this gesture\n",

    "\n",
    "                    # Collect data from each cycle for this gesture\n",
    "                    for rep in range(1, 6):  # Assuming 5 cycles, named as 'Cycle1', 'Cycle2', ...\n",
    "                        cycle_group_name = f'Cycle{rep}/Gesture{gesture_names[gesture]}'\n",
    "                        if cycle_group_name in hdf_read:\n",
    "                            # Read and append the data\n",
    "                            cycle_data = hdf_read[cycle_group_name]['sEMG'][:]\n",
    "                            all_cycles_data.append(cycle_data)\n",
    "\n",
    "                    # Aggregate all cycles data into a single array (CYCLE, CHANNELS, TIME)\n",
    "                    # hdf5 keys are named as 'Gesture{gesture_name}'    \n",
    "                    if all_cycles_data:  # Ensure there is data to process\n",
    "                        aggregated_data = np.stack(all_cycles_data, axis=0)  # Stack along new axis for cycles\n",
    "\n",
    "                        # Write the aggregated data to the new file\n",
    "                        hdf_write.create_dataset(f'Gesture{gesture_names[gesture]}', data=aggregated_data, compression=\"gzip\")\n",
    "        except FileExistsError as e:\n",
    "            print(f\"File {hdf5_output_filename} already exists. Skipping...\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            continue\n",
    "            \n",
    "            \n",
    "\n",
    "    print(f\"Reprocessed data saved in {hdf5_output_filename}.\")"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 8,

   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['GestureAbduction', 'GestureAdduction', 'GestureExtension', 'GestureFlexion', 'GestureGrip', 'GesturePronation', 'GestureRadial_Deviation', 'GestureRest', 'GestureSupination', 'GestureUlnar_Deviation']>\n",
      "(5, 4, 10000)\n",
      "(5, 4, 10000)\n",
      "(5, 4, 10000)\n",
      "(5, 4, 10000)\n",
      "(5, 4, 10000)\n",
      "(5, 4, 10000)\n",
      "(5, 4, 10000)\n",
      "(5, 4, 10000)\n",
      "(5, 4, 10000)\n",
      "(5, 4, 10000)\n"
     ]
    }
   ],
   "source": [

    "gesture_names = ['Rest', 'Extension', 'Flexion', 'Ulnar_Deviation', 'Radial_Deviation', 'Grip', 'Abduction', 'Adduction', 'Supination', 'Pronation']\n",
    "foldername = 'DatasetsProcessed_hdf5/OzdemirEMG/p40/'\n",
    "hdf5_filename = 'flattened_participant_40.hdf5'\n",

    "hdf5_filename = os.path.join(foldername, hdf5_filename)\n",
    "with h5py.File(hdf5_filename, 'r') as hdf_file:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % hdf_file.keys())\n",
    "    a_group_key = list(hdf_file.keys())[0]\n",
    "\n",
    "    #print(hdf_file['GestureRest'].shape)\n",
    "    for name in gesture_names:\n",
    "        print(hdf_file[\"Gesture\" + name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 10)\n",
      "[480, 480, 480, 480, 480, 480, 480, 480, 480, 480]\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import butter, filtfilt, iirnotch\n",
    "gesture_names = ['Rest', 'Extension', 'Flexion', 'Ulnar_Deviation', 'Radial_Deviation', 'Grip', 'Abduction', 'Adduction', 'Supination', 'Pronation']\n",
    "numGestures = 10\n",
    "fs = 2000 #Hz\n",
    "wLen = 250 # ms\n",
    "wLenTimesteps = int(wLen / 1000 * fs)\n",
    "stepLen = 100 #50 ms\n",
    "def filter(emg):\n",
    "    # sixth-order Butterworth highpass filter\n",
    "    b, a = butter(N=3, Wn=[5.0, 500.0], btype='bandpass', analog=False, fs=2000.0)\n",
    "    emgButter = torch.from_numpy(np.flip(filtfilt(b, a, emg),axis=0).copy())\n",
    "\n",
    "    #second-order notch filter at 50â€¯Hz\n",
    "    b, a = iirnotch(w0=50.0, Q=0.0001, fs=2000.0)\n",
    "    return torch.from_numpy(np.flip(filtfilt(b, a, emgButter),axis=0).copy())\n",
    "\n",
    "# Check flattened data\n",
    "def getEMG (n):\n",
    "    file = h5py.File('DatasetsProcessed_hdf5/OzdemirEMG/p40/flattened_participant_40.hdf5', 'r')\n",
    "    emg = []\n",
    "    for gesture in gesture_names:\n",
    "        data = filter(torch.from_numpy(np.array(file[\"Gesture\" + gesture]))).unfold(dimension=-1, size=wLenTimesteps, step=stepLen)\n",
    "        emg.append(torch.cat([data[i] for i in range(len(data))], dim=-2).permute((1, 0, 2)))\n",
    "    return torch.cat(emg, dim=0)\n",
    "\n",
    "# size of 4800 assumes 250 ms window\n",
    "def getLabels (n):\n",
    "    labels = np.zeros((4800, numGestures))\n",
    "    for i in range(480):\n",
    "        for j in range(numGestures):\n",
    "            labels[j * 480 + i][j] = 1.0\n",
    "    return labels\n",
    "\n",
    "'''for i in range(40):\n",
    "    data = getEMG(i)\n",
    "    print(data.shape)'''\n",
    "\n",
    "labels = getLabels(20)\n",
    "numEach = [0 for i in range(10)]\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(labels[0])):\n",
    "        if (labels[i][j] != 0):\n",
    "            numEach[j] += 1\n",
    "\n",
    "print(labels.shape)\n",
    "print(numEach)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd69f43f58546b570e94fd7eba7b65e6bcc7a5bbc4eab0408017d18902915d69"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
